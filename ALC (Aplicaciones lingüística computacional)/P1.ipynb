{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_iHs6RkPPurz"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fechas = re.compile( \"\\d{2,} de (?:enero|febrero|marzo|abril|mayo|junio|julio|agosto|septiembre|octubre|noviembre|diciembre) de \\d{4,}\", re.I | re.U)\n",
        "acronimos = re.compile('(?:[A-Z]+\\.)+')\n",
        "emojis = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
        "url = re.compile('(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})')\n",
        "coma_sin_espacios = re.compile('(\\w*,[a-zA-Z]+)')\n",
        "general = re.compile(r\"\\b\\S+\\b|[(),\\'\\\"?Â¿!Â¡:;%]|\\.+|^\\d*[.,]?\\d*|\\S+@\\S+|\\d{1,2}:\\d{2}[h]?|\\d{1,2}(?:|-)\\d{2}(?:|-)\\d{2,4}|@\\S+|#\\S+\")"
      ],
      "metadata": {
        "id": "aN_SWAEvPzU3"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/data/entrada_tokenizador.txt', 'r') as file:\n",
        "    input = file.read()"
      ],
      "metadata": {
        "id": "MCUxMbMhRb-2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZLpOWRMSFPm",
        "outputId": "d81a3826-5bbb-48d4-f8e9-66bf14ff9b32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã‰l, Antonio, no vendrÃ¡ maÃ±ana: lo harÃ¡ pasado maÃ±ana.  Â¿Â¿Â¿Â¿CuÃ¡ndo???? No te lo he dicho... Â¡?Vale! no te he oido.\n",
            "De acuerdo; No irÃ©. Pesa 44.44 kg y mide 32,32 m. El 12-12-2020, y el 13/12: habrÃ¡ examen, el 14-12 ya veremos.\n",
            "El pseudo-cÃ³digo vale 30,6 sobre 100. El 15.5% no es suficiente. El \"bote\" estÃ¡ lleno, o 'vacio' no semi-vacio.\n",
            "Â¡Ay! el correo es fpla@dsic.upv.es y la web: http://users.dsic.upv.es/~fpla/ se me olvidaba, ha cambiado. Ahora es http://personales.upv.es/~fpla/ \n",
            "MaÃ±ana nos vemos a las 9:30 horas. 3/4 partes de la poblaciÃ³n come carne.\n",
            "el usuario @antonio_123 escribiÃ³ un tweet con el hashtag #alc-2019 el viernes, https://haha.ls-ps.com\n",
            "El 14 de marzo de 2021 empiezan las clases de LNRI de prÃ¡cticas y alguna cosa mÃ¡s.\n",
            "Todo lo que sigue son ejemplos de acrÃ³nimos que no se deberÃ­an separar: EE.UU., S.L., CC.OO., S.A., D., U.R.S.S., entre otros.\n",
            "PodÃ©is probar con otros ejemplos, e incluso, plantear algÃºn tipo de tokens que os interese: disfrutaaaddd!!!!! ðŸ™‚ \n",
            "'ðŸ¤” ðŸ™ˆ es asÃ­,bla, bla, bla  ðŸŽ“ es, se . ðŸ˜Œ de...; ðŸ’•ðŸ‘­ðŸ‘™ðŸ˜Š'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/data/salida_tokenizador.txt', 'r') as file:\n",
        "    output_esperado = file.read()"
      ],
      "metadata": {
        "id": "qZX_w7XqSdfO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_esperado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afs_6ZVnVGT_",
        "outputId": "37a4ae3b-dc3c-4010-d526-a4b2b9382999"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã‰l, Antonio, no vendrÃ¡ maÃ±ana: lo harÃ¡ pasado maÃ±ana.  Â¿Â¿Â¿Â¿CuÃ¡ndo???? No te lo he dicho... Â¡?Vale! no te he oido.\n",
            "\n",
            "Ã‰l\n",
            ",\n",
            "Antonio\n",
            ",\n",
            "no\n",
            "vendrÃ¡\n",
            "maÃ±ana\n",
            ":\n",
            "lo\n",
            "harÃ¡\n",
            "pasado\n",
            "maÃ±ana\n",
            ".\n",
            "Â¿\n",
            "Â¿\n",
            "Â¿\n",
            "Â¿\n",
            "CuÃ¡ndo\n",
            "?\n",
            "?\n",
            "?\n",
            "?\n",
            "No\n",
            "te\n",
            "lo\n",
            "he\n",
            "dicho\n",
            "...\n",
            "Â¡\n",
            "?\n",
            "Vale\n",
            "!\n",
            "no\n",
            "te\n",
            "he\n",
            "oido\n",
            ".\n",
            "De acuerdo; No irÃ©. Pesa 44.44 kg y mide 32,32 m. El 12-12-2020, y el 13/12: habrÃ¡ examen, el 14-12 ya veremos.\n",
            "\n",
            "De\n",
            "acuerdo\n",
            ";\n",
            "No\n",
            "irÃ©\n",
            ".\n",
            "Pesa\n",
            "44.44\n",
            "kg\n",
            "y\n",
            "mide\n",
            "32,32\n",
            "m\n",
            ".\n",
            "El\n",
            "12-12-2020\n",
            ",\n",
            "y\n",
            "el\n",
            "13/12\n",
            ":\n",
            "habrÃ¡\n",
            "examen\n",
            ",\n",
            "el\n",
            "14-12\n",
            "ya\n",
            "veremos\n",
            ".\n",
            "El pseudo-cÃ³digo vale 30,6 sobre 100. El 15.5% no es suficiente. El \"bote\" estÃ¡ lleno, o 'vacio' no semi-vacio.\n",
            "\n",
            "El\n",
            "pseudo-cÃ³digo\n",
            "vale\n",
            "30,6\n",
            "sobre\n",
            "100\n",
            ".\n",
            "El\n",
            "15.5\n",
            "%\n",
            "no\n",
            "es\n",
            "suficiente\n",
            ".\n",
            "El\n",
            "\"\n",
            "bote\n",
            "\"\n",
            "estÃ¡\n",
            "lleno\n",
            ",\n",
            "o\n",
            "'\n",
            "vacio\n",
            "'\n",
            "no\n",
            "semi-vacio\n",
            ".\n",
            "Â¡Ay! el correo es fpla@dsic.upv.es y la web: http://users.dsic.upv.es/~fpla/ se me olvidaba, ha cambiado. Ahora es http://personales.upv.es/~fpla/ \n",
            "\n",
            "Â¡\n",
            "Ay\n",
            "!\n",
            "el\n",
            "correo\n",
            "es\n",
            "fpla@dsic.upv.es\n",
            "y\n",
            "la\n",
            "web\n",
            ":\n",
            "http://users.dsic.upv.es/~fpla/\n",
            "se\n",
            "me\n",
            "olvidaba\n",
            ",\n",
            "ha\n",
            "cambiado\n",
            ".\n",
            "Ahora\n",
            "es\n",
            "http://personales.upv.es/~fpla/\n",
            "MaÃ±ana nos vemos a las 9:30 horas. 3/4 partes de la poblaciÃ³n come carne.\n",
            "\n",
            "MaÃ±ana\n",
            "nos\n",
            "vemos\n",
            "a\n",
            "las\n",
            "9:30\n",
            "horas\n",
            ".\n",
            "3/4\n",
            "partes\n",
            "de\n",
            "la\n",
            "poblaciÃ³n\n",
            "come\n",
            "carne\n",
            ".\n",
            "el usuario @antonio_123 escribiÃ³ un tweet con el hashtag #alc-2019 el viernes, https://haha.ls-ps.com\n",
            "\n",
            "el\n",
            "usuario\n",
            "@antonio_123\n",
            "escribiÃ³\n",
            "un\n",
            "tweet\n",
            "con\n",
            "el\n",
            "hashtag\n",
            "#alc-2019\n",
            "el\n",
            "viernes\n",
            ",\n",
            "https://haha.ls-ps.com\n",
            "El 14 de marzo de 2021 empiezan las clases de LNRI de prÃ¡cticas y alguna cosa mÃ¡s.\n",
            "\n",
            "El\n",
            "14 de marzo de 2021\n",
            "empiezan\n",
            "las\n",
            "clases\n",
            "de\n",
            "LNRI\n",
            "de\n",
            "prÃ¡cticas\n",
            "y\n",
            "alguna\n",
            "cosa\n",
            "mÃ¡s\n",
            ".\n",
            "Todo lo que sigue son ejemplos de acrÃ³nimos que no se deberÃ­an separar: EE.UU., S.L., CC.OO., S.A., D., U.R.S.S., entre otros.\n",
            "\n",
            "Todo\n",
            "lo\n",
            "que\n",
            "sigue\n",
            "son\n",
            "ejemplos\n",
            "de\n",
            "acrÃ³nimos\n",
            "que\n",
            "no\n",
            "se\n",
            "deberÃ­an\n",
            "separar\n",
            ":\n",
            "EE.UU.\n",
            ",\n",
            "S.L.\n",
            ",\n",
            "CC.OO.\n",
            ",\n",
            "S.A.\n",
            ",\n",
            "D.\n",
            ",\n",
            "U.R.S.S.\n",
            ",\n",
            "entre\n",
            "otros\n",
            ".\n",
            "PodÃ©is probar con otros ejemplos, e incluso, plantear algÃºn tipo de tokens que os interese: disfrutaaaddd!!!!! ðŸ™‚ \n",
            "\n",
            "PodÃ©is\n",
            "probar\n",
            "con\n",
            "otros\n",
            "ejemplos\n",
            ",\n",
            "e\n",
            "incluso\n",
            ",\n",
            "plantear\n",
            "algÃºn\n",
            "tipo\n",
            "de\n",
            "tokens\n",
            "que\n",
            "os\n",
            "interese\n",
            ":\n",
            "disfrutaaaddd\n",
            "!\n",
            "!\n",
            "!\n",
            "!\n",
            "!\n",
            "ðŸ™‚\n",
            "'ðŸ¤” ðŸ™ˆ es asÃ­,bla, bla, bla  ðŸŽ“ es, se . ðŸ˜Œ de...; ðŸ’•ðŸ‘­ðŸ‘™ðŸ˜Š'\n",
            "\n",
            "'\n",
            "ðŸ¤”\n",
            "ðŸ™ˆ\n",
            "es\n",
            "asÃ­\n",
            ",\n",
            "bla\n",
            ",\n",
            "bla\n",
            ",\n",
            "bla\n",
            "ðŸŽ“\n",
            "es\n",
            ",\n",
            "se\n",
            ".\n",
            "ðŸ˜Œ\n",
            "de\n",
            "...\n",
            ";\n",
            "ðŸ’•\n",
            "ðŸ‘­\n",
            "ðŸ‘™\n",
            "ðŸ˜Š\n",
            "'\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizacion = \"\"\n",
        "for frase in input.split('\\n'):\n",
        "  print(frase)\n",
        "  tokenizacion += frase + '\\n'\n",
        "  dates = fechas.findall(frase)\n",
        "  frase = re.sub(fechas, \"FECHA\", frase)\n",
        "  acros = acronimos.findall(frase)\n",
        "  frase = re.sub(acronimos, \"ACRONIMO\", frase)\n",
        "  iconos = emojis.findall(frase)\n",
        "  frase = re.sub(emojis, \"EMOJI\", frase)\n",
        "  urls = url.findall(frase)\n",
        "  frase = re.sub(url, \"URL\", frase)\n",
        "  strings_coma_sin_espacios = coma_sin_espacios.findall(frase)\n",
        "  frase = re.sub(coma_sin_espacios, \"COMA_SIN_ESPACIOS\", frase)\n",
        "  print(frase)\n",
        "  for token in general.findall(frase):\n",
        "    #print(token)\n",
        "    if token == \"ACRONIMO\":\n",
        "        acro = acros.pop(0)\n",
        "        tokenizacion += \"\\n\" + acro\n",
        "    elif token == \"FECHA\":\n",
        "        date = dates.pop(0)\n",
        "        tokenizacion += \"\\n\" + date\n",
        "    elif token == \"EMOJI\":\n",
        "        emoji = iconos.pop(0)\n",
        "        tokenizacion += \"\\n\" + emoji\n",
        "    elif token == \"URL\":\n",
        "        unrul = urls.pop(0)\n",
        "        tokenizacion += \"\\n\" + unrul\n",
        "    elif \"EMOJI\" in token:\n",
        "      n  = 5\n",
        "      cadena_emojis = []\n",
        "      for index in range(0, len(token), n):\n",
        "        cadena_emojis.append(token[index : index + n])\n",
        "      for i in cadena_emojis:\n",
        "        emoji = iconos.pop(0)\n",
        "        tokenizacion += \"\\n\" + emoji\n",
        "    elif \"COMA_SIN_ESPACIOS\" in token:\n",
        "      result = []\n",
        "      for e in strings_coma_sin_espacios.pop(0).split(','):\n",
        "        result.append(e)\n",
        "        result.append(',')\n",
        "      result.pop()\n",
        "      for palabra in result:\n",
        "        tokenizacion += \"\\n\" + palabra\n",
        "    else:\n",
        "        tokenizacion += \"\\n\" + token\n",
        "  tokenizacion += '\\n' \n",
        "tokenizacion = tokenizacion[:len(tokenizacion)-2]     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYbdhXynP7ax",
        "outputId": "52c3eb9e-94a3-4c17-f33d-12011c234a26"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã‰l, Antonio, no vendrÃ¡ maÃ±ana: lo harÃ¡ pasado maÃ±ana.  Â¿Â¿Â¿Â¿CuÃ¡ndo???? No te lo he dicho... Â¡?Vale! no te he oido.\n",
            "Ã‰l, Antonio, no vendrÃ¡ maÃ±ana: lo harÃ¡ pasado maÃ±ana.  Â¿Â¿Â¿Â¿CuÃ¡ndo???? No te lo he dicho... Â¡?Vale! no te he oido.\n",
            "De acuerdo; No irÃ©. Pesa 44.44 kg y mide 32,32 m. El 12-12-2020, y el 13/12: habrÃ¡ examen, el 14-12 ya veremos.\n",
            "De acuerdo; No irÃ©. Pesa 44.44 kg y mide 32,32 m. El 12-12-2020, y el 13/12: habrÃ¡ examen, el 14-12 ya veremos.\n",
            "El pseudo-cÃ³digo vale 30,6 sobre 100. El 15.5% no es suficiente. El \"bote\" estÃ¡ lleno, o 'vacio' no semi-vacio.\n",
            "El pseudo-cÃ³digo vale 30,6 sobre 100. El 15.5% no es suficiente. El \"bote\" estÃ¡ lleno, o 'vacio' no semi-vacio.\n",
            "Â¡Ay! el correo es fpla@dsic.upv.es y la web: http://users.dsic.upv.es/~fpla/ se me olvidaba, ha cambiado. Ahora es http://personales.upv.es/~fpla/ \n",
            "Â¡Ay! el correo es fpla@dsic.upv.es y la web: URL se me olvidaba, ha cambiado. Ahora es URL \n",
            "MaÃ±ana nos vemos a las 9:30 horas. 3/4 partes de la poblaciÃ³n come carne.\n",
            "MaÃ±ana nos vemos a las 9:30 horas. 3/4 partes de la poblaciÃ³n come carne.\n",
            "el usuario @antonio_123 escribiÃ³ un tweet con el hashtag #alc-2019 el viernes, https://haha.ls-ps.com\n",
            "el usuario @antonio_123 escribiÃ³ un tweet con el hashtag #alc-2019 el viernes, URL\n",
            "El 14 de marzo de 2021 empiezan las clases de LNRI de prÃ¡cticas y alguna cosa mÃ¡s.\n",
            "El FECHA empiezan las clases de LNRI de prÃ¡cticas y alguna cosa mÃ¡s.\n",
            "Todo lo que sigue son ejemplos de acrÃ³nimos que no se deberÃ­an separar: EE.UU., S.L., CC.OO., S.A., D., U.R.S.S., entre otros.\n",
            "Todo lo que sigue son ejemplos de acrÃ³nimos que no se deberÃ­an separar: ACRONIMO, ACRONIMO, ACRONIMO, ACRONIMO, ACRONIMO, ACRONIMO, entre otros.\n",
            "PodÃ©is probar con otros ejemplos, e incluso, plantear algÃºn tipo de tokens que os interese: disfrutaaaddd!!!!! ðŸ™‚ \n",
            "PodÃ©is probar con otros ejemplos, e incluso, plantear algÃºn tipo de tokens que os interese: disfrutaaaddd!!!!! EMOJI \n",
            "'ðŸ¤” ðŸ™ˆ es asÃ­,bla, bla, bla  ðŸŽ“ es, se . ðŸ˜Œ de...; ðŸ’•ðŸ‘­ðŸ‘™ðŸ˜Š'\n",
            "'EMOJI EMOJI es COMA_SIN_ESPACIOS, bla, bla  EMOJI es, se . EMOJI de...; EMOJIEMOJIEMOJIEMOJI'\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizacion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhxp70SqQNcr",
        "outputId": "2e81dec7-9b5e-43c5-c88c-e797b8fffb89"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã‰l, Antonio, no vendrÃ¡ maÃ±ana: lo harÃ¡ pasado maÃ±ana.  Â¿Â¿Â¿Â¿CuÃ¡ndo???? No te lo he dicho... Â¡?Vale! no te he oido.\n",
            "\n",
            "Ã‰l\n",
            ",\n",
            "Antonio\n",
            ",\n",
            "no\n",
            "vendrÃ¡\n",
            "maÃ±ana\n",
            ":\n",
            "lo\n",
            "harÃ¡\n",
            "pasado\n",
            "maÃ±ana\n",
            ".\n",
            "Â¿\n",
            "Â¿\n",
            "Â¿\n",
            "Â¿\n",
            "CuÃ¡ndo\n",
            "?\n",
            "?\n",
            "?\n",
            "?\n",
            "No\n",
            "te\n",
            "lo\n",
            "he\n",
            "dicho\n",
            "...\n",
            "Â¡\n",
            "?\n",
            "Vale\n",
            "!\n",
            "no\n",
            "te\n",
            "he\n",
            "oido\n",
            ".\n",
            "De acuerdo; No irÃ©. Pesa 44.44 kg y mide 32,32 m. El 12-12-2020, y el 13/12: habrÃ¡ examen, el 14-12 ya veremos.\n",
            "\n",
            "De\n",
            "acuerdo\n",
            ";\n",
            "No\n",
            "irÃ©\n",
            ".\n",
            "Pesa\n",
            "44.44\n",
            "kg\n",
            "y\n",
            "mide\n",
            "32,32\n",
            "m\n",
            ".\n",
            "El\n",
            "12-12-2020\n",
            ",\n",
            "y\n",
            "el\n",
            "13/12\n",
            ":\n",
            "habrÃ¡\n",
            "examen\n",
            ",\n",
            "el\n",
            "14-12\n",
            "ya\n",
            "veremos\n",
            ".\n",
            "El pseudo-cÃ³digo vale 30,6 sobre 100. El 15.5% no es suficiente. El \"bote\" estÃ¡ lleno, o 'vacio' no semi-vacio.\n",
            "\n",
            "El\n",
            "pseudo-cÃ³digo\n",
            "vale\n",
            "30,6\n",
            "sobre\n",
            "100\n",
            ".\n",
            "El\n",
            "15.5\n",
            "%\n",
            "no\n",
            "es\n",
            "suficiente\n",
            ".\n",
            "El\n",
            "\"\n",
            "bote\n",
            "\"\n",
            "estÃ¡\n",
            "lleno\n",
            ",\n",
            "o\n",
            "'\n",
            "vacio\n",
            "'\n",
            "no\n",
            "semi-vacio\n",
            ".\n",
            "Â¡Ay! el correo es fpla@dsic.upv.es y la web: http://users.dsic.upv.es/~fpla/ se me olvidaba, ha cambiado. Ahora es http://personales.upv.es/~fpla/ \n",
            "\n",
            "Â¡\n",
            "Ay\n",
            "!\n",
            "el\n",
            "correo\n",
            "es\n",
            "fpla@dsic.upv.es\n",
            "y\n",
            "la\n",
            "web\n",
            ":\n",
            "http://users.dsic.upv.es/~fpla/\n",
            "se\n",
            "me\n",
            "olvidaba\n",
            ",\n",
            "ha\n",
            "cambiado\n",
            ".\n",
            "Ahora\n",
            "es\n",
            "http://personales.upv.es/~fpla/\n",
            "MaÃ±ana nos vemos a las 9:30 horas. 3/4 partes de la poblaciÃ³n come carne.\n",
            "\n",
            "MaÃ±ana\n",
            "nos\n",
            "vemos\n",
            "a\n",
            "las\n",
            "9:30\n",
            "horas\n",
            ".\n",
            "3/4\n",
            "partes\n",
            "de\n",
            "la\n",
            "poblaciÃ³n\n",
            "come\n",
            "carne\n",
            ".\n",
            "el usuario @antonio_123 escribiÃ³ un tweet con el hashtag #alc-2019 el viernes, https://haha.ls-ps.com\n",
            "\n",
            "el\n",
            "usuario\n",
            "@antonio_123\n",
            "escribiÃ³\n",
            "un\n",
            "tweet\n",
            "con\n",
            "el\n",
            "hashtag\n",
            "#alc-2019\n",
            "el\n",
            "viernes\n",
            ",\n",
            "https://haha.ls-ps.com\n",
            "El 14 de marzo de 2021 empiezan las clases de LNRI de prÃ¡cticas y alguna cosa mÃ¡s.\n",
            "\n",
            "El\n",
            "14 de marzo de 2021\n",
            "empiezan\n",
            "las\n",
            "clases\n",
            "de\n",
            "LNRI\n",
            "de\n",
            "prÃ¡cticas\n",
            "y\n",
            "alguna\n",
            "cosa\n",
            "mÃ¡s\n",
            ".\n",
            "Todo lo que sigue son ejemplos de acrÃ³nimos que no se deberÃ­an separar: EE.UU., S.L., CC.OO., S.A., D., U.R.S.S., entre otros.\n",
            "\n",
            "Todo\n",
            "lo\n",
            "que\n",
            "sigue\n",
            "son\n",
            "ejemplos\n",
            "de\n",
            "acrÃ³nimos\n",
            "que\n",
            "no\n",
            "se\n",
            "deberÃ­an\n",
            "separar\n",
            ":\n",
            "EE.UU.\n",
            ",\n",
            "S.L.\n",
            ",\n",
            "CC.OO.\n",
            ",\n",
            "S.A.\n",
            ",\n",
            "D.\n",
            ",\n",
            "U.R.S.S.\n",
            ",\n",
            "entre\n",
            "otros\n",
            ".\n",
            "PodÃ©is probar con otros ejemplos, e incluso, plantear algÃºn tipo de tokens que os interese: disfrutaaaddd!!!!! ðŸ™‚ \n",
            "\n",
            "PodÃ©is\n",
            "probar\n",
            "con\n",
            "otros\n",
            "ejemplos\n",
            ",\n",
            "e\n",
            "incluso\n",
            ",\n",
            "plantear\n",
            "algÃºn\n",
            "tipo\n",
            "de\n",
            "tokens\n",
            "que\n",
            "os\n",
            "interese\n",
            ":\n",
            "disfrutaaaddd\n",
            "!\n",
            "!\n",
            "!\n",
            "!\n",
            "!\n",
            "ðŸ™‚\n",
            "'ðŸ¤” ðŸ™ˆ es asÃ­,bla, bla, bla  ðŸŽ“ es, se . ðŸ˜Œ de...; ðŸ’•ðŸ‘­ðŸ‘™ðŸ˜Š'\n",
            "\n",
            "'\n",
            "ðŸ¤”\n",
            "ðŸ™ˆ\n",
            "es\n",
            "asÃ­\n",
            ",\n",
            "bla\n",
            ",\n",
            "bla\n",
            ",\n",
            "bla\n",
            "ðŸŽ“\n",
            "es\n",
            ",\n",
            "se\n",
            ".\n",
            "ðŸ˜Œ\n",
            "de\n",
            "...\n",
            ";\n",
            "ðŸ’•\n",
            "ðŸ‘­\n",
            "ðŸ‘™\n",
            "ðŸ˜Š\n",
            "'\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizacion == output_esperado:\n",
        "  print('TokenizaciÃ³n correcta')\n",
        "else:\n",
        "  frases1 = [frase for frase in tokenizacion.split('\\n')]\n",
        "  frases2 = [frase for frase in output_esperado.split('\\n')]\n",
        "  for i, frase in enumerate (frases2):\n",
        "    print(frases1[i])\n",
        "    print(frases2[i])\n",
        "    if frases1[i]!=frases2[i]:\n",
        "      print('no coindicide la ' + str(i))\n",
        "      print('tokenizado: ' + frases1[i])\n",
        "      print('esperado: ' + frases2[i])\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbko4HjzVVAu",
        "outputId": "7739e5e3-3a23-4c1d-dae4-29b1e210cd9b"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TokenizaciÃ³n correcta\n"
          ]
        }
      ]
    }
  ]
}